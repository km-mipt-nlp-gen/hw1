# Отчет о выполнении задания "№1. Разработка Retrieval-Based чат-бота"

## Содержание отчета

1. Описание входных данных ([ссылка](#1-описание-входных-данных))
2. Описание артефактов (выходных файлов) ([ссылка](#2-описание-артефактов))
3. Указание структуры проекта (включая файлы, доступные в GitHub и по ссылкам)
4. Графики обучения и валидации моделей с комментариями
5. Текст логов обучения и валидации моделей
6. Ссылки на ноутбуки со всеми графиками, логами и тестами:
   1. Ноутбук препроцессинга данных
   2. Ноутбук скачивания ML кода с GitHub и запуска обучения и валидации моделей, генерации артефактов
   3. Ноутбук скачивания кода Web-приложения с GitHub, запуска интеграционного тестирования, а также старта приложения
7. Описание использования моделей (классы, методы, ресурсы реализующие логику выдачи ответов)
8. Ускорение вывода, а также итеративный процесс улучшений проекта (опыт, выводы, подходы и методы)

---

## 1 описание входных данных

В качестве входных данных используются диалоги из сериала "The Simpsons".
Можно разделить входные данные на 2 блока: сырые до предобработки в исходном виде, и также данные после обработки.
### 1.1 Описание исходных данных:
- файл по пути *ml/data/raw/script_lines.csv*
- столбцы - id, episode_id, number, raw_text, timestamp_in_ms, speaking_line, character_id, location_id, raw_character_text, raw_location_text, spoken_words, normalized_text, word_count;
- кол-во записей - 158267;
- каждая запись содержит данные полей указанных выше для реплики из сериала;
- распределение реплик по персонажам представлено на диаграмме ниже
![img.png](chat_quotes_distribution.png)
- в четверку лидеров входит **Lisa Simpson, именно этот персонаж выбран в качестве роли для чат-бота**;
- наиболее информативным полем является поле raw_text с именем персонажа и репликой, для кросс-проверки данных также использовались другие поля (например, character_id);
### 1.2 Описание предобработанных данных:
- получены предобработанные файлы:
  - qa_pairs.joblib (данные реплик обогащены тремя предыдущими, сохранена текущая реплика, а также метка принадлежности к целевому персонажу Lisa Simpson);
  - target_char_answers.joblib (аналогично target_char_qa_pairs.joblib, но лишь ответы);
  - target_char_qa_pairs.joblib (аналогично qa_pairs.joblib, но отфильтрованы ответы целевого персонажа, поле контекста сохранено);
- несколько нюансов про предобработку данных - в пункте 8 ("итеративный процесс улучшений");
- по итогам предобработки реплики были обогащены контекстом (предыдущими репликами), причем группировка производилась по эпизоду и локации (например, автомобиль, магазин);
- запуск предобработки производился в ноутбуке (это единственный случай в этом проекте, когда не выделялись классы и модули py, хотя подкачивался файл с постоянными полями).
## 2-описание-артефактов:
- модели по итогам обучения, сохранены в формате pth, ссылки представлены в файле *ml/asset/model/models_links.info*, ниже снимок файлов моделей в хранилище;
![img_2.png](models_screenshot.png)
- эмбеддинги (siamese-bi-encoder) по пути *ml/asset/embedding*, см. про использование в пункте 8:
  - *ml/asset/embedding/target_char_answers_embeddings.joblib* (ответы целевого персонажа);
  - *ml/asset/embedding/target_char_qa_pairs_embeddings.joblib* (ответы целевого персонажа и предыдущие реплики, mean_pool);
  - *ml/asset/embedding/target_char_qa_pairs_faiss_index.joblib* (FAISS GPU индекс на основе target_char_qa_pairs_embeddings);
  - *ml/asset/embedding/target_char_qa_pairs_faiss_psa_index.joblib* (FAISS GPU индекс с уменьшением размерности, аналогичен предыдущему);
- токенизатор ('distilbert-base-uncased') по пути *ml/asset/tokenizer/tokenizer.joblib* - для повторяемости вывода;